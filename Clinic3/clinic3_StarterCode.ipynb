{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "hide": true
   },
   "source": [
    "# KEN3450, Data Analysis, Spring 2020\n",
    "\n",
    "### Clinic 3: Classification in Python\n",
    "\n",
    "**Add your name and i-number here and any other disclaimer info.**\n",
    "\n",
    "**Check the honor policy code posted on the portal before reusing code you found online**\n",
    "\n",
    "***\n",
    "### Learning Goals:\n",
    "\n",
    "By the end of this clinic, you should be able to:\n",
    "\n",
    "* Run Classification Models (Logistic Regression, Decision Trees, Random Forests, etc.) in Python\n",
    "* Explain and tackle issues like missing values or class inbalance in your dataset\n",
    "* Judge the results of a classification model using AUROC scores\n",
    "* Select a proper algorithm that works well with your data using techniques (see also last week) like:\n",
    "    * Cross Validation\n",
    "    * Regularization\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:34.369146Z",
     "start_time": "2020-03-02T19:36:32.815220Z"
    },
    "hide": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.api import OLS\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "%matplotlib inline\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Determine the Inbalance (Asymmetry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we would like to notice in our data that they are highly unbalanced (assymetric). Load the data which should contain 9 columns (`health`, `age`, `sex`, `educ`, `sexornt`, `partyid`, `race`, `married`, `income`). `Age`, `educ` (how many years of education a person has) and `income` are quantitative, the others are qualitative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:34.417012Z",
     "start_time": "2020-03-02T19:36:34.370117Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>educ</th>\n",
       "      <th>sexornt</th>\n",
       "      <th>partyid</th>\n",
       "      <th>race</th>\n",
       "      <th>married</th>\n",
       "      <th>income</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent</td>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>rep</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>18750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent</td>\n",
       "      <td>26</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>rep</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>18750.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>59</td>\n",
       "      <td>male</td>\n",
       "      <td>13</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>rep</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excellent</td>\n",
       "      <td>74</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poor</td>\n",
       "      <td>37</td>\n",
       "      <td>female</td>\n",
       "      <td>10</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      health  age     sex  educ                   sexornt partyid   race  \\\n",
       "0  excellent   53    male    16  heterosexual or straight     rep  white   \n",
       "1  excellent   26  female    16  heterosexual or straight     rep  white   \n",
       "2       good   59    male    13  heterosexual or straight     rep  white   \n",
       "3  excellent   74  female    17  heterosexual or straight   other  white   \n",
       "4       poor   37  female    10  heterosexual or straight   other  white   \n",
       "\n",
       "   married   income  \n",
       "0        1  18750.0  \n",
       "1        1  18750.0  \n",
       "2        1      NaN  \n",
       "3        1      NaN  \n",
       "4        0      NaN  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gssdata=pd.read_csv(\"gssdata4.csv\")\n",
    "gssdata.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to predict if a person is in poor health or not. Let's create some dummy variables in order to measure that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:34.424964Z",
     "start_time": "2020-03-02T19:36:34.417984Z"
    }
   },
   "outputs": [],
   "source": [
    "poorhealth = np.where(gssdata['health'] == 'poor',1,0)\n",
    "excellenthealth = np.where(gssdata['health'] == 'excellent',1,0)\n",
    "fairhealth = np.where(gssdata['health'] == 'fair',1,0)\n",
    "gssdata['poorhealth'] = poorhealth\n",
    "gssdata['fairhealth'] = fairhealth\n",
    "gssdata['excellenthealth'] = excellenthealth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:34.453887Z",
     "start_time": "2020-03-02T19:36:34.425963Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of          health  age     sex  educ                   sexornt partyid   race  \\\n",
       "0     excellent   53    male    16  heterosexual or straight     rep  white   \n",
       "1     excellent   26  female    16  heterosexual or straight     rep  white   \n",
       "2          good   59    male    13  heterosexual or straight     rep  white   \n",
       "3     excellent   74  female    17  heterosexual or straight   other  white   \n",
       "4          poor   37  female    10  heterosexual or straight   other  white   \n",
       "5     excellent   30  female    15  heterosexual or straight   other  other   \n",
       "6          fair   43  female     5  heterosexual or straight   other  other   \n",
       "7          poor   56    male    11  heterosexual or straight   other  white   \n",
       "8          good   69    male     8  heterosexual or straight   other  white   \n",
       "9     excellent   30  female    14  heterosexual or straight   other  black   \n",
       "10         good   42  female    11  heterosexual or straight     dem  white   \n",
       "11    excellent   38    male    14  heterosexual or straight     dem  other   \n",
       "12         good   38  female    15  heterosexual or straight     dem  white   \n",
       "13    excellent   28  female    18  heterosexual or straight     dem  black   \n",
       "14         good   35    male    13  heterosexual or straight   other  white   \n",
       "15         good   50    male    15  heterosexual or straight     dem  white   \n",
       "16    excellent   54    male    16  heterosexual or straight     dem  white   \n",
       "17         good   61  female    16  heterosexual or straight     dem  white   \n",
       "18         good   54  female    16  heterosexual or straight     rep  white   \n",
       "19         good   37  female    12                 dont know   other  black   \n",
       "20         good   38  female    11  heterosexual or straight   other  other   \n",
       "21         fair   69  female    10  heterosexual or straight     rep  white   \n",
       "22         good   35    male    16  heterosexual or straight     dem  white   \n",
       "23         good   61  female    17  heterosexual or straight     rep  white   \n",
       "24         poor   59    male    11  heterosexual or straight   other  white   \n",
       "25    excellent   50  female    16  heterosexual or straight     rep  white   \n",
       "26         good   43  female    12  heterosexual or straight     dem  black   \n",
       "27    excellent   30    male    15  heterosexual or straight     rep  white   \n",
       "28    excellent   59    male    11  heterosexual or straight     dem  white   \n",
       "29         good   32  female    15  heterosexual or straight     dem  white   \n",
       "...         ...  ...     ...   ...                       ...     ...    ...   \n",
       "1521       good   29    male    11  heterosexual or straight     dem  black   \n",
       "1522       good   46  female    11  heterosexual or straight     dem  black   \n",
       "1523       poor   83  female    11  heterosexual or straight     dem  white   \n",
       "1524       fair   25  female    14  heterosexual or straight     rep  white   \n",
       "1525  excellent   43  female    12  heterosexual or straight     dem  white   \n",
       "1526       good   43    male    12  heterosexual or straight   other  white   \n",
       "1527       good   35  female    12  heterosexual or straight   other  white   \n",
       "1528  excellent   67  female    14  heterosexual or straight     rep  white   \n",
       "1529       fair   88  female    12  heterosexual or straight     dem  white   \n",
       "1530       fair   54  female    11  heterosexual or straight     rep  white   \n",
       "1531       good   41  female    14  heterosexual or straight   other  white   \n",
       "1532       fair   46    male    12  heterosexual or straight     dem  white   \n",
       "1533       good   54  female    12  heterosexual or straight   other  white   \n",
       "1534  excellent   34  female    14  heterosexual or straight     dem  white   \n",
       "1535  excellent   36  female    12  heterosexual or straight   other  white   \n",
       "1536       good   65    male    16  heterosexual or straight     dem  white   \n",
       "1537  excellent   48  female    16  heterosexual or straight     dem  white   \n",
       "1538       fair   30    male    14  heterosexual or straight     dem  white   \n",
       "1539  excellent   48  female    18  heterosexual or straight     rep  white   \n",
       "1540       good   49  female    12  heterosexual or straight     rep  white   \n",
       "1541       good   54    male    16  heterosexual or straight     dem  white   \n",
       "1542       good   49    male    16  heterosexual or straight     rep  white   \n",
       "1543       good   54    male    12  heterosexual or straight     rep  white   \n",
       "1544       good   62    male    12  heterosexual or straight     rep  white   \n",
       "1545       fair   75  female    14  heterosexual or straight     rep  white   \n",
       "1546       good   89  female    14  heterosexual or straight     rep  white   \n",
       "1547       good   56    male    12  heterosexual or straight   other  white   \n",
       "1548  excellent   24    male    14  heterosexual or straight     dem  white   \n",
       "1549       fair   27    male    13  heterosexual or straight     dem  white   \n",
       "1550       good   71  female    12  heterosexual or straight     rep  white   \n",
       "\n",
       "      married   income  poorhealth  fairhealth  excellenthealth  \n",
       "0           1  18750.0           0           0                1  \n",
       "1           1  18750.0           0           0                1  \n",
       "2           1      NaN           0           0                0  \n",
       "3           1      NaN           0           0                1  \n",
       "4           0      NaN           1           0                0  \n",
       "5           1  18750.0           0           0                1  \n",
       "6           1      NaN           0           1                0  \n",
       "7           0      NaN           1           0                0  \n",
       "8           1      NaN           0           0                0  \n",
       "9           1  16250.0           0           0                1  \n",
       "10          1      NaN           0           0                0  \n",
       "11          0      NaN           0           0                1  \n",
       "12          0  18750.0           0           0                0  \n",
       "13          0      NaN           0           0                1  \n",
       "14          1  16250.0           0           0                0  \n",
       "15          1  18750.0           0           0                0  \n",
       "16          1  18750.0           0           0                1  \n",
       "17          1  18750.0           0           0                0  \n",
       "18          0      NaN           0           0                0  \n",
       "19          1  16250.0           0           0                0  \n",
       "20          0   9000.0           0           0                0  \n",
       "21          1      NaN           0           1                0  \n",
       "22          1  18750.0           0           0                0  \n",
       "23          1      NaN           0           0                0  \n",
       "24          0      NaN           1           0                0  \n",
       "25          1  18750.0           0           0                1  \n",
       "26          0  18750.0           0           0                0  \n",
       "27          0  18750.0           0           0                1  \n",
       "28          1  18750.0           0           0                1  \n",
       "29          1  18750.0           0           0                0  \n",
       "...       ...      ...         ...         ...              ...  \n",
       "1521        0      NaN           0           0                0  \n",
       "1522        0  11250.0           0           0                0  \n",
       "1523        1      NaN           1           0                0  \n",
       "1524        0   7500.0           0           1                0  \n",
       "1525        1      NaN           0           0                1  \n",
       "1526        1  16250.0           0           0                0  \n",
       "1527        1      NaN           0           0                0  \n",
       "1528        1      NaN           0           0                1  \n",
       "1529        1      NaN           0           1                0  \n",
       "1530        1      NaN           0           1                0  \n",
       "1531        1  16250.0           0           0                0  \n",
       "1532        1  18750.0           0           1                0  \n",
       "1533        1      NaN           0           0                0  \n",
       "1534        1  13750.0           0           0                1  \n",
       "1535        1      NaN           0           0                1  \n",
       "1536        1  18750.0           0           0                0  \n",
       "1537        1  16250.0           0           0                1  \n",
       "1538        0   4500.0           0           1                0  \n",
       "1539        1   9000.0           0           0                1  \n",
       "1540        1  18750.0           0           0                0  \n",
       "1541        1  18750.0           0           0                0  \n",
       "1542        1  18750.0           0           0                0  \n",
       "1543        1  18750.0           0           0                0  \n",
       "1544        1  18750.0           0           0                0  \n",
       "1545        1      NaN           0           1                0  \n",
       "1546        1      NaN           0           0                0  \n",
       "1547        1  18750.0           0           0                0  \n",
       "1548        0  11250.0           0           0                1  \n",
       "1549        0  18750.0           0           1                0  \n",
       "1550        1  16250.0           0           0                0  \n",
       "\n",
       "[1551 rows x 12 columns]>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gssdata.describe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to make the task easier, we will consider it as a binary classification problem, where we are actually interested into predicting the people that are in poor health (class `poorhealth`) vs. the others (classes `fairhealth` and `excellenthealth` combined).\n",
    "\n",
    "Can you quantify what is the degree of inbalance? Mention a percentage of the split between the positive and the negative class.\n",
    "\n",
    "* What is the majority and the minority class?\n",
    "* What would be the accuracy of a classifier that predicts everybody NOT being in poor health?\n",
    "* Discuss why accuracy is not a good metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:34.471773Z",
     "start_time": "2020-03-02T19:36:34.455882Z"
    }
   },
   "outputs": [],
   "source": [
    "####HERE YOU CAN ADD CODE AND MORE COMMENTS\n",
    "####\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Fit a logistic model ignoring missing values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's begin by fitting a logistic regression model to predict poor health based on several of the other predictors in the model. In part 3, you will be asked to regularize (with cross-validation) to make sure you do not overfit, but for this part, we will keep things simple.\n",
    "\n",
    "First, we need to do a small amount of data clean-up (ignoring missingness for now in `income`). Best practice would be to split into train/test first before looking at the data, but again, we can keep it simple in this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:34.998911Z",
     "start_time": "2020-03-02T19:36:34.973179Z"
    }
   },
   "outputs": [],
   "source": [
    "#creating dummies two ways\n",
    "gssdata['female'] = 1*(gssdata['sex'] ==  'female')\n",
    "dummy_vars = pd.get_dummies(gssdata[['sexornt','partyid','race']])\n",
    "gssdata = gssdata.join(dummy_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:35.285285Z",
     "start_time": "2020-03-02T19:36:35.261347Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1551, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>health</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>educ</th>\n",
       "      <th>sexornt</th>\n",
       "      <th>partyid</th>\n",
       "      <th>race</th>\n",
       "      <th>married</th>\n",
       "      <th>income</th>\n",
       "      <th>poorhealth</th>\n",
       "      <th>...</th>\n",
       "      <th>sexornt_bisexual</th>\n",
       "      <th>sexornt_dont know</th>\n",
       "      <th>sexornt_heterosexual or straight</th>\n",
       "      <th>sexornt_homosexual or gay</th>\n",
       "      <th>partyid_dem</th>\n",
       "      <th>partyid_other</th>\n",
       "      <th>partyid_rep</th>\n",
       "      <th>race_black</th>\n",
       "      <th>race_other</th>\n",
       "      <th>race_white</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>excellent</td>\n",
       "      <td>53</td>\n",
       "      <td>male</td>\n",
       "      <td>16</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>rep</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>18750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>excellent</td>\n",
       "      <td>26</td>\n",
       "      <td>female</td>\n",
       "      <td>16</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>rep</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>18750.0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>good</td>\n",
       "      <td>59</td>\n",
       "      <td>male</td>\n",
       "      <td>13</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>rep</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>excellent</td>\n",
       "      <td>74</td>\n",
       "      <td>female</td>\n",
       "      <td>17</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>poor</td>\n",
       "      <td>37</td>\n",
       "      <td>female</td>\n",
       "      <td>10</td>\n",
       "      <td>heterosexual or straight</td>\n",
       "      <td>other</td>\n",
       "      <td>white</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      health  age     sex  educ                   sexornt partyid   race  \\\n",
       "0  excellent   53    male    16  heterosexual or straight     rep  white   \n",
       "1  excellent   26  female    16  heterosexual or straight     rep  white   \n",
       "2       good   59    male    13  heterosexual or straight     rep  white   \n",
       "3  excellent   74  female    17  heterosexual or straight   other  white   \n",
       "4       poor   37  female    10  heterosexual or straight   other  white   \n",
       "\n",
       "   married   income  poorhealth  ...  sexornt_bisexual  sexornt_dont know  \\\n",
       "0        1  18750.0           0  ...                 0                  0   \n",
       "1        1  18750.0           0  ...                 0                  0   \n",
       "2        1      NaN           0  ...                 0                  0   \n",
       "3        1      NaN           0  ...                 0                  0   \n",
       "4        0      NaN           1  ...                 0                  0   \n",
       "\n",
       "   sexornt_heterosexual or straight  sexornt_homosexual or gay  partyid_dem  \\\n",
       "0                                 1                          0            0   \n",
       "1                                 1                          0            0   \n",
       "2                                 1                          0            0   \n",
       "3                                 1                          0            0   \n",
       "4                                 1                          0            0   \n",
       "\n",
       "   partyid_other  partyid_rep  race_black  race_other  race_white  \n",
       "0              0            1           0           0           1  \n",
       "1              0            1           0           0           1  \n",
       "2              0            1           0           0           1  \n",
       "3              1            0           0           0           1  \n",
       "4              1            0           0           0           1  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Let's get a sense of the data we have\n",
    "print(gssdata.shape)\n",
    "gssdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:35.551846Z",
     "start_time": "2020-03-02T19:36:35.548858Z"
    }
   },
   "outputs": [],
   "source": [
    "######HERE YOUR CODE TO FIT THE MODEL\n",
    "######\n",
    "######\n",
    "######Look up LogisticRegression() from scikitlearn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2a: Handling missingness approach \\#1: remove observations. \n",
    "\n",
    "We do not know how sklearn will treat the missing values (the `NaN`s), so we should do handle them ourselves.  As a base case, let's remove all observations with missingness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:36.653864Z",
     "start_time": "2020-03-02T19:36:36.384623Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-e9a993733080>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m#Do a quick check to see how dropping observations affected the amount of poor health individuals\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m#Do an appropriate plot to show this (e.g. boxplot)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbarplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mgssdata_full\u001b[0m \u001b[1;31m#<---this should be your final data frame.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'd' is not defined"
     ]
    }
   ],
   "source": [
    "##In the code below: Remove all observations that are not complete\n",
    "##Report on how many samples were dropped.\n",
    "\n",
    "#Do a quick check to see how dropping observations affected the amount of poor health individuals\n",
    "#Do an appropriate plot to show this (e.g. boxplot)\n",
    "sns.barplot(x=d.index,y=d.values)\n",
    "\n",
    "gssdata_full #<---this should be your final data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-02T19:36:36.853982Z",
     "start_time": "2020-03-02T19:36:36.843994Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gssdata_full' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-a051ece00f7c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mitrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgssdata_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.25\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#gsstemp = gssdata_full.drop(['health','fairhealth','goodhealth','excellenthealth','sex','sexornt','partyid','race'],axis=1)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gssdata_full' is not defined"
     ]
    }
   ],
   "source": [
    "#Now we will split the data before fitting any models, feel free to change this/adapt this to your taste\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "itrain, itest = train_test_split(range(gssdata_full.shape[0]), test_size=0.25)\n",
    "\n",
    "#gsstemp = gssdata_full.drop(['health','fairhealth','goodhealth','excellenthealth','sex','sexornt','partyid','race'],axis=1)\n",
    "gsstemp = gssdata_full[['age','educ','female','partyid_dem','partyid_rep','income']]\n",
    "\n",
    "X_train = gsstemp.iloc[itrain, :]\n",
    "X_test = gsstemp.iloc[itest, :]\n",
    "y_train = gssdata_full['poorhealth'].iloc[itrain]\n",
    "y_test = gssdata_full['poorhealth'].iloc[itest]\n",
    "\n",
    "y_train.shape, X_train.shape, y_test.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# Your code here: fit a logistic model with C=1000000 and evaluate classification accuracy on the test set.\n",
    "# Then move below to be reminded on the confusion matrix\n",
    "#####################\n",
    "\n",
    "\n",
    "logit #<-- this should be the name of your model so as to work below with the confusion matrix \n",
    "      #(or if you have a different name, then change it there as well)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reminder: The Confusion Matrix & Some Useful Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- the samples that are +ive and the classifier predicts as +ive are called True Positives (TP)\n",
    "- the samples that are -ive and the classifier predicts (wrongly) as +ive are called False Positives (FP)\n",
    "- the samples that are -ive and the classifier predicts as -ive are called True Negatives (TN)\n",
    "- the samples that are +ive and the classifier predicts as -ive are called False Negatives (FN)\n",
    "\n",
    "A classifier produces a confusion matrix which looks like this:\n",
    "\n",
    "![confusionmatrix](./confusionmatrix_360.png)\n",
    "\n",
    "\n",
    "IMPORTANT NOTE: In sklearn, to obtain the confusion matrix in the form above, always have the observed `y` first, i.e.: use as `confusion_matrix(y_true, y_pred)`\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test,logit.predict(X_test)))\n",
    "\n",
    "yhats = logit.predict_proba(X_train)\n",
    "hist = plt.hist(yhats[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following function can be used to create confusion tables with different thresholds (same as we did in the last example of the lecture slides)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###manually making confusion table from a different threshold\n",
    "def t_repredict(est, t, xtest):\n",
    "    probs = est.predict_proba(xtest)\n",
    "    p0 = probs[:,0]\n",
    "    p1 = probs[:,1]\n",
    "    ypred = (p1 > t)*1\n",
    "    return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Try it here!\n",
    "\n",
    "print(confusion_matrix(y_test,t_repredict(logit, 0.06, X_test)))\n",
    "print(confusion_matrix(y_train,t_repredict(logit, 0.06, X_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following fuction should create ROC curves for your models, based on the model and the ground truth. Feel free to change it and improve it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making ROC curves for this model\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "\n",
    "#name: name of your model to appear on the figure (can be arbitrary)\n",
    "#clf: the model as you named it - will be used for getting the predictions\n",
    "#ytest, xtest: your test data\n",
    "#skip, labe: steps that control how many points you see in the ROC curve and how many labels are there\n",
    "\n",
    "def make_roc(name, clf, ytest, xtest, ax=None, labe=5, proba=True, skip=0):\n",
    "    initial=False\n",
    "    if not ax:\n",
    "        ax=plt.gca()\n",
    "        initial=True\n",
    "    if proba:#for stuff like logistic regression\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.predict_proba(xtest)[:,1])\n",
    "    else:#for stuff like SVM? (but double-check this pleaseee)\n",
    "        fpr, tpr, thresholds=roc_curve(ytest, clf.decision_function(xtest))\n",
    "    \n",
    "    #this is the single value for the AUC score\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "    \n",
    "    if skip: \n",
    "        l=fpr.shape[0]\n",
    "        ax.plot(fpr[0:l:skip], tpr[0:l:skip], '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    else:\n",
    "        ax.plot(fpr, tpr, '.-', alpha=0.3, label='ROC curve for %s (area = %0.2f)' % (name, roc_auc))\n",
    "    \n",
    "    label_kwargs = {}\n",
    "    label_kwargs['bbox'] = dict(\n",
    "        boxstyle='round,pad=0.3', alpha=0.2,\n",
    "    )\n",
    "    \n",
    "    #add labels to the curve\n",
    "    if labe!=None:\n",
    "        for k in range(0, fpr.shape[0],labe):\n",
    "            #from https://gist.github.com/podshumok/c1d1c9394335d86255b8\n",
    "            threshold = str(np.round(thresholds[k], 2))\n",
    "            ax.annotate(threshold, (fpr[k], tpr[k]), **label_kwargs)\n",
    "    \n",
    "    if initial:\n",
    "        ax.plot([0, 1], [0, 1], 'k--')\n",
    "        ax.set_xlim([0.0, 1.0])\n",
    "        ax.set_ylim([0.0, 1.05])\n",
    "        ax.set_xlabel('False Positive Rate')\n",
    "        ax.set_ylabel('True Positive Rate')\n",
    "        ax.set_title('ROC')\n",
    "    ax.legend(loc=\"lower right\")\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is how the above function should be used\n",
    "\n",
    "sns.set_context(\"poster\")\n",
    "ax=make_roc(\"logistic\",logit, y_test, X_test, labe=4, skip=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's get back the data with missingness\n",
    "\n",
    "It's time to build a model to impute the missing data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#first build a model to impute using data without missing \n",
    "hist = plt.hist(gssdata_full['income'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2b: Handling missingness approach \\#2: impute the mean "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In your first approach, make a copy of the original data frame and impute the missing values by assuming that every missing value shoudl be replaced by the mean. Make sure to do a histogram as well and compare it with the original!\n",
    "\n",
    "Then fit a model (as before in 2a.) and judge the model accuracy. Use the functions for the ROC curve to establish the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#back to the original data set with missingness, make a copy, and then impute the mean, plot it!\n",
    "###YOUR CODE HERE\n",
    "###\n",
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "###here, do a proper train/test split and a model training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "#your code here: create confusion tables for some thresholds to have an idea of how data looks like\n",
    "#####################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# your code here: create an ROC curve\n",
    "#####################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will comment on the performance of the models in the end, but feel free to add any comments here as well (or remove this cell)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2c: Handling missingness approach \\#3: impute with a model (linear regression here)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third and most sophisticated approach would be to fit a linear model (multiple regression) to estimate income based on the other features (`age`, `educ`, `sex`, `partyid`). Train this model below and then use it in order to compute the missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#use the dataset without NAs here\n",
    "#train a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#####################\n",
    "# your code here: \n",
    "# 1. figure out which observations have missing values for income,\n",
    "# 2. create the values you will use for imputation by:\n",
    "#  - calculating (1) the predicted values for the observations with missingness using the linear model \n",
    "# 3. use these values to impute back into the income variable in the missing entries\n",
    "# 4. Do a histogram to see how does that look like\n",
    "#####################\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then fill the missing data with the results you got. You can do that multiple ways, one way to use Python would be the following:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#you might need to change some of the variables below, but in principle it should work\n",
    "missing_index = gssdata.income[gssdata.income.isnull()].index\n",
    "missing_series = pd.Series(data = y_missing_noise, index = missing_index)\n",
    "#back to the data set with missingness and impute the predictions\n",
    "gssdata_imp = gssdata.copy()\n",
    "gssdata_imp['income'] = gssdata_imp['income'].fillna(missing_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HERE FIT YOUR MODEL AS USUAL FOR PREDICTING THE HEALTH STATUS (POOR OR NOT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAKE CONFUSION TABLES FOR DIFFERENT THRESHOLDS AND DRAW THE AUROC CURVE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "Which model performs the best when it comes to missing values? Use this cell to report your observations and be critical about them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Improving the model.\n",
    "\n",
    "Apply regularization (with cross-validation) to make sure not to overfit to the data and try also different models, like a Decision Tree or a Random Forest. Report on your results for which model handles inbalances in the best way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your comments go here. Make sure you document and comment on each step of your approach. Also, make sure that you sufficiently comment on the results and be critical. Which approach worked the best? How did they handle missingness?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
